{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf43481-f377-4e0a-9eb0-850940b762b1",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYSPARK_DRIVER_PYTHON=C:\\Python311\\python.exe\n"
     ]
    }
   ],
   "source": [
    "# %env SPARK_HOME=C:\\MapProdQA\\spark-3.5.0-bin-hadoop3\n",
    "# %env SPARK_HOME=C:\\Python311\\Lib\\site-packages\\pyspark\n",
    "# %env HADOOP_HOME=C:\\MapProdQA\\spark-3.5.0-bin-hadoop3\n",
    "# %env HADOOP_HOME=C:\\Users\\anilk\\Downloads\\hadoop-2.8.1\n",
    "# %env JAVA_HOME=\"C:\\Program Files\\Amazon Corretto\\jdk1.8.0_282\"\n",
    "# %env PATH=%PATH%;%SPARK_HOME%\\bin\n",
    "# %env PYTHONPATH=%PYTHONPATH%;\"%SPARK_HOME%\\python\"\n",
    "# %env PYTHONPATH=%PYTHONPATH%;\"%SPARK_HOME%\\python\\lib\\*.zip\"\n",
    "\n",
    "# optional\n",
    "# %env PYSPARK_PYTHON=python\n",
    "%env PYSPARK_DRIVER_PYTHON=C:\\Python311\\python.exe\n",
    "# %env PYSPARK_DRIVER_PYTHON=jupyter \n",
    "# %env PYSPARK_DRIVER_PYTHON_OPTS=notebook\n",
    "# %env SPARK_REMOTE=\"\"\n",
    "# PYTHONPATH=$SPARK_HOME$\\python;$SPARK_HOME$\\python\\lib\\py4j-<version>-src.zip\n",
    "# %env PYSPARK_SUBMIT_ARGS=--master local[1] pyspark-shell\n",
    "# %env PYSPARK_SUBMIT_ARGS=C:\\MapProdQA\\Python3.9\\Lib\\site-packages\\pyspark\\jars\\*.jar\n",
    "# %env SPARK_CLASSPATH=C:\\MapProdQA\\Python3.9\\Lib\\site-packages\\pyspark\\jars\\*.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd12a663-fe90-4570-888f-45727140a613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Spark\\spark-3.5.1-bin-hadoop3\n",
      "%PYSPARK_PYTHON%\n",
      "C:\\Hadoop\\hadoop-3.3.6\\\n",
      "C:\\Program Files\\Java\\jdk-17\n",
      "C:\\Users\\lucio\\AppData\\Local\\Programs\\Python\\Python312;C:\\Users\\lucio\\AppData\\Local\\Programs\\Python\\Python312\n",
      "%PYSPARK_DRIVER_PYTHON%\n",
      "%PYSPARK_SUBMIT_ARGS%\n"
     ]
    }
   ],
   "source": [
    "!echo %SPARK_HOME% \n",
    "!echo %PYSPARK_PYTHON% \n",
    "!echo %HADOOP_HOME% \n",
    "!echo %JAVA_HOME% \n",
    "!echo %PYTHONPATH%\n",
    "!echo %PYSPARK_DRIVER_PYTHON%\n",
    "!echo %PYSPARK_SUBMIT_ARGS%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e74c78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "import os\n",
    "import pandas as pd\n",
    "# set the environment variables\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "122297e3-6b42-49e2-ad6e-50d0abe4c4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x23451d46f60>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F \n",
    "from IPython.display import display\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName('PySparkShell').getOrCreate()\n",
    "# set master to local{*} to tell that local machine is the master node\n",
    "\n",
    "# https://stackoverflow.com/questions/46125604/databricks-display-function-equivalent-or-alternative-to-jupyter\n",
    "# While practise, to see the dataframe without .show(). This will enable the display()\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce826244-9877-4ae6-9898-5a0c9f8ed441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>Name</th><th>Geometry</th></tr>\n",
       "<tr><td>Place1</td><td>MULTIPOINT ((19.5...</td></tr>\n",
       "<tr><td>Place2</td><td>LINESTRING (10 10...</td></tr>\n",
       "<tr><td>Place3</td><td>MULTIPOINT ((19.5...</td></tr>\n",
       "<tr><td>Place4</td><td>MULTIPOLYGON (((0...</td></tr>\n",
       "<tr><td>Place5</td><td>LINESTRING (10 10...</td></tr>\n",
       "<tr><td>Place6</td><td>POLYGON ((19.5112...</td></tr>\n",
       "<tr><td>Place7</td><td>POLYGON ((19.5112...</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------+--------------------+\n",
       "|  Name|            Geometry|\n",
       "+------+--------------------+\n",
       "|Place1|MULTIPOINT ((19.5...|\n",
       "|Place2|LINESTRING (10 10...|\n",
       "|Place3|MULTIPOINT ((19.5...|\n",
       "|Place4|MULTIPOLYGON (((0...|\n",
       "|Place5|LINESTRING (10 10...|\n",
       "|Place6|POLYGON ((19.5112...|\n",
       "|Place7|POLYGON ((19.5112...|\n",
       "+------+--------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to read csv from spark\n",
    "path = \"data.csv\"\n",
    "output_path = \"output_data.csv\"\n",
    "import sys\n",
    "\n",
    "df = spark.read.csv(path, inferSchema=True, header=True)\n",
    "\n",
    "# to save a csv\n",
    "df.write.format('csv').mode(\"overwrite\").option(\"header\",True).save(os.path.join(os.getcwd(), 'new_data.csv'))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f48a1c7-3fd7-4bdf-8171-e37aa35217c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>geometry_type</th><th>geometry_instance_count</th></tr>\n",
       "<tr><td>ST_MultiPolygon</td><td>1</td></tr>\n",
       "<tr><td>ST_LineString</td><td>2</td></tr>\n",
       "<tr><td>ST_MultiPoint</td><td>2</td></tr>\n",
       "<tr><td>ST_Polygon</td><td>2</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------------+-----------------------+\n",
       "|  geometry_type|geometry_instance_count|\n",
       "+---------------+-----------------------+\n",
       "|ST_MultiPolygon|                      1|\n",
       "|  ST_LineString|                      2|\n",
       "|  ST_MultiPoint|                      2|\n",
       "|     ST_Polygon|                      2|\n",
       "+---------------+-----------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from sedona.register import SedonaRegistrator\n",
    "from sedona.spark import *\n",
    "path = 'data.csv'\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    appName('appName'). \\\n",
    "    config('spark.jars.packages',\n",
    "           'org.apache.sedona:sedona-spark-shaded-3.0_2.12:1.5.0,'\n",
    "           'org.datasyslab:geotools-wrapper:1.5.0-28.2'). \\\n",
    "    getOrCreate()\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "SedonaContext.create(spark)\n",
    "df = spark.read.csv(path, inferSchema=True, header=True)\n",
    "df.createOrReplaceTempView(\"realdf\")\n",
    "df1 = spark.sql(\n",
    "    '''SELECT ST_GeometryType(ST_GeomFromText(geometry)) as geometry_type,\n",
    "    COUNT(SUBSTRING_INDEX(geometry, ' ', 1)) AS geometry_instance_count \n",
    "    FROM realdf \n",
    "    WHERE geometry is NOT NULL\n",
    "    GROUP BY geometry_type''')\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "434f47be-0626-400e-aabb-8ca8e14ec760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------------+\n",
      "|  geometry_type|geometry_instance_count|\n",
      "+---------------+-----------------------+\n",
      "|ST_MultiPolygon|                      1|\n",
      "|  ST_LineString|                      2|\n",
      "|  ST_MultiPoint|                      2|\n",
      "|     ST_Polygon|                      2|\n",
      "+---------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "079fb381-6706-4b04-a24a-b44485cc5252",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n",
    "spark.sparkContext.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
